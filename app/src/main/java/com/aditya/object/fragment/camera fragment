package com.aditya.`object`.fragment

import android.animation.Animator
import android.animation.AnimatorListenerAdapter
import android.animation.AnimatorSet
import android.animation.ObjectAnimator
import android.content.ActivityNotFoundException
import android.content.Intent
import android.graphics.Bitmap
import android.graphics.BitmapFactory
import android.graphics.ImageFormat
import android.graphics.Rect
import android.graphics.Typeface
import android.graphics.YuvImage
import android.hardware.usb.UsbDevice
import android.os.*
import android.provider.MediaStore
import android.speech.RecognitionListener
import android.speech.RecognizerIntent
import android.speech.SpeechRecognizer
import android.speech.tts.TextToSpeech
import android.util.Log
import android.view.Gravity
import android.view.LayoutInflater
import android.view.View
import android.view.ViewGroup
import android.widget.PopupWindow
import android.widget.SeekBar
import android.widget.TextView
import android.widget.Toast
import androidx.core.view.children
import androidx.core.widget.TextViewCompat
import androidx.lifecycle.lifecycleScope
import com.aditya.`object`.ObjectDetectorHelper
import com.aditya.`object`.R
import com.aditya.`object`.databinding.FragmentUsbBinding
import com.afollestad.materialdialogs.MaterialDialog
import com.afollestad.materialdialogs.list.listItemsSingleChoice
import com.google.mlkit.vision.common.InputImage
import com.google.mlkit.vision.text.TextRecognition
import com.google.mlkit.vision.text.TextRecognizer
import com.google.mlkit.vision.text.latin.TextRecognizerOptions
import com.jiangdg.ausbc.MultiCameraClient
import com.jiangdg.ausbc.base.CameraFragment
import com.jiangdg.ausbc.callback.ICameraStateCallBack
import com.jiangdg.ausbc.callback.ICaptureCallBack
import com.jiangdg.ausbc.callback.IPlayCallBack
import com.jiangdg.ausbc.callback.IPreviewDataCallBack
import com.jiangdg.ausbc.camera.CameraUVC
import com.jiangdg.ausbc.render.effect.EffectBlackWhite
import com.jiangdg.ausbc.render.effect.EffectSoul
import com.jiangdg.ausbc.render.effect.EffectZoom
import com.jiangdg.ausbc.render.effect.bean.CameraEffect
import com.jiangdg.ausbc.utils.*
import com.jiangdg.ausbc.utils.bus.BusKey
import com.jiangdg.ausbc.utils.bus.EventBus
import com.jiangdg.ausbc.widget.*
import kotlinx.coroutines.*
import org.tensorflow.lite.task.vision.detector.Detection
import java.io.ByteArrayOutputStream
import java.io.File
import java.util.*
import java.util.concurrent.Executors

class UsbFragment : CameraFragment(), View.OnClickListener, CaptureMediaView.OnViewClickListener {
    private var mMoreMenu: PopupWindow? = null
    private var isCapturingVideoOrAudio: Boolean = false
    private var isPlayingMic: Boolean = false
    private var mRecTimer: Timer? = null
    private var mRecSeconds = 0
    private var mRecMinute = 0
    private var mRecHours = 0
    private lateinit var objectDetectorHelper: ObjectDetectorHelper
    private lateinit var textToSpeech: TextToSpeech
    private lateinit var textRecognizer: TextRecognizer
    private var isObjectDetectionActive: Boolean = false
    private var isTextRecognitionActive: Boolean = false
    private val inferenceDispatcher = Executors.newSingleThreadExecutor().asCoroutineDispatcher()
    private val speechQueue: Queue<String> = LinkedList()
    private var lastSpokenTime: Long = 0
    private val MIN_SPEECH_INTERVAL_MS = 2000L
    private val SPEECH_RECOGNITION_DELAY = 1000L // 1-second delay between recognitions

    // Add a SpeechRecognizer variable
    private lateinit var speechRecognizer: SpeechRecognizer

    private var previousDetections: MutableSet<String> = mutableSetOf()

    private val mCameraModeTabMap = mapOf(
        CaptureMediaView.CaptureMode.MODE_CAPTURE_PIC to R.id.takePictureModeTv,
        CaptureMediaView.CaptureMode.MODE_CAPTURE_VIDEO to R.id.recordVideoModeTv,
        CaptureMediaView.CaptureMode.MODE_CAPTURE_AUDIO to R.id.recordAudioModeTv
    )

    private val ttsListener = TextToSpeech.OnUtteranceCompletedListener {
        if (speechQueue.isNotEmpty()) {
            val nextText = speechQueue.poll()
            textToSpeech.speak(nextText, TextToSpeech.QUEUE_FLUSH, null, nextText.hashCode().toString())
        }
    }

    // Initialize SpeechRecognizer and start listening
    private fun initSpeechRecognizer() {
        speechRecognizer = SpeechRecognizer.createSpeechRecognizer(requireContext())
        speechRecognizer.setRecognitionListener(object : RecognitionListener {
            override fun onReadyForSpeech(params: Bundle?) {
                ToastUtils.showToast(requireContext(), "Listening for voice command...")
            }

            override fun onBeginningOfSpeech() {}
            override fun onRmsChanged(rmsdB: Float) {}
            override fun onBufferReceived(buffer: ByteArray?) {}
            override fun onEndOfSpeech() {}

            override fun onError(error: Int) {
                Log.e(TAG, "Speech recognition error: $error")
                if (error == SpeechRecognizer.ERROR_RECOGNIZER_BUSY) {
                    // Handle busy recognizer error
                    ToastUtils.showToast(requireContext(), "Recognizer busy, retrying...")
                } else {
                    ToastUtils.showToast(requireContext(), "Error recognizing speech, please try again.")
                }

                // Restart listening on error with a delay
                lifecycleScope.launch {
                    delay(SPEECH_RECOGNITION_DELAY)  // Delay before retrying
                    startListeningForVoiceCommand()
                }
            }

            override fun onResults(results: Bundle?) {
                val matches = results?.getStringArrayList(SpeechRecognizer.RESULTS_RECOGNITION)
                matches?.let {
                    for (result in it) {
                        Log.d(TAG, "Voice command detected: $result")
                        handleVoiceCommand(result)  // Handle the voice command
                    }
                }
                // Restart listening after processing the command
                startListeningForVoiceCommand()
            }

            override fun onPartialResults(partialResults: Bundle?) {}
            override fun onEvent(eventType: Int, params: Bundle?) {}
        })
    }


    private fun startListeningForVoiceCommand() {
        val intent = Intent(RecognizerIntent.ACTION_RECOGNIZE_SPEECH).apply {
            putExtra(RecognizerIntent.EXTRA_LANGUAGE_MODEL, RecognizerIntent.LANGUAGE_MODEL_FREE_FORM)
            putExtra(RecognizerIntent.EXTRA_LANGUAGE, Locale.getDefault())
            putExtra(RecognizerIntent.EXTRA_PROMPT, "Say 'object' to start detection or 'stop' to stop detection")
        }

        try {
            speechRecognizer.startListening(intent)
        } catch (e: ActivityNotFoundException) {
            Log.e(TAG, "Speech recognition not supported on this device: ${e.message}")
            Toast.makeText(requireContext(), "Speech recognition not supported on this device", Toast.LENGTH_SHORT).show()
        }
    }

    // Method to handle voice commands
    private fun handleVoiceCommand(command: String) {
        when (command.toLowerCase(Locale.ROOT)) {
            "object" -> {
                if (!isObjectDetectionActive) {
                    stopTextDetection()
                    startObjectDetection()
                }
            }
            "scan" -> {
                if (!isTextRecognitionActive) {
                    stopObjectDetection()
                    startTextDetection()
                }
            }
            "stop" -> {
                stopAllDetections()
            }
            else -> {
                Log.d(TAG, "Unknown command: $command")
            }
        }
    }

    private val mEffectDataList by lazy {
        arrayListOf(
            CameraEffect.NONE_FILTER,
            CameraEffect(
                EffectBlackWhite.ID,
                "BlackWhite",
                CameraEffect.CLASSIFY_ID_FILTER,
                effect = EffectBlackWhite(requireActivity()),
                coverResId = R.mipmap.filter0
            ),
            CameraEffect.NONE_ANIMATION,
            CameraEffect(
                EffectZoom.ID,
                "Zoom",
                CameraEffect.CLASSIFY_ID_ANIMATION,
                effect = EffectZoom(requireActivity()),
                coverResId = R.mipmap.filter2
            ),
            CameraEffect(
                EffectSoul.ID,
                "Soul",
                CameraEffect.CLASSIFY_ID_ANIMATION,
                effect = EffectSoul(requireActivity()),
                coverResId = R.mipmap.filter1
            ),
        )
    }

    private lateinit var mViewBinding: FragmentUsbBinding
    private var mCameraMode = CaptureMediaView.CaptureMode.MODE_CAPTURE_PIC

    private val mMainHandler: Handler by lazy {
        Handler(Looper.getMainLooper()) {
            when (it.what) {
                WHAT_START_TIMER -> {
                    if (mRecSeconds % 2 != 0) {
                        mViewBinding.recStateIv.visibility = View.VISIBLE
                    } else {
                        mViewBinding.recStateIv.visibility = View.INVISIBLE
                    }
                    mViewBinding.recTimeTv.text = calculateTime(mRecSeconds, mRecMinute)
                }
                WHAT_STOP_TIMER -> {
                    mViewBinding.modeSwitchLayout.visibility = View.VISIBLE
                    mViewBinding.toolbarGroup.visibility = View.VISIBLE
                    mViewBinding.albumPreviewIv.visibility = View.VISIBLE
                    mViewBinding.lensFacingBtn1.visibility = View.VISIBLE
                    mViewBinding.recTimerLayout.visibility = View.GONE
                    mViewBinding.recTimeTv.text = calculateTime(0, 0)
                }
            }
            true
        }
    }

    override fun onViewCreated(view: View, savedInstanceState: Bundle?) {
        super.onViewCreated(view, savedInstanceState)
        textToSpeech = TextToSpeech(requireContext()) { status ->
            if (status == TextToSpeech.SUCCESS) {
                textToSpeech.language = Locale.US
                textToSpeech.setSpeechRate(0.8f)
                textToSpeech.setPitch(1.0f)
                textToSpeech.setOnUtteranceCompletedListener(ttsListener)
            }
        }

        textRecognizer = TextRecognition.getClient(TextRecognizerOptions.Builder().build())

        initObjectDetector()

        initSpeechRecognizer()
        startListeningForVoiceCommand()
    }

    private fun shouldSpeakNow(): Boolean {
        val currentTime = System.currentTimeMillis()
        return if (currentTime - lastSpokenTime >= MIN_SPEECH_INTERVAL_MS) {
            lastSpokenTime = currentTime
            true
        } else {
            false
        }
    }

    private fun startObjectDetection() {
        if (!isObjectDetectionActive) {  // Check if already active
            isObjectDetectionActive = true
            Toast.makeText(requireContext(), "Object Detection Started", Toast.LENGTH_SHORT).show()

            // Add any necessary setup for object detection
            getCurrentCamera()?.addPreviewDataCallBack(object : IPreviewDataCallBack {
                override fun onPreviewData(
                    data: ByteArray?,
                    width: Int,
                    height: Int,
                    format: IPreviewDataCallBack.DataFormat
                ) {
                    Log.d(TAG, "Preview Data Received: Width = $width, Height = $height, Format = $format")
                    processFrame(data, width, height, format)
                }
            })
        }
    }

    private fun processFrame(data: ByteArray?, width: Int, height: Int, format: IPreviewDataCallBack.DataFormat) {
        data ?: return

        Log.d(TAG, "Processing frame with width: $width, height: $height, format: $format")

        lifecycleScope.launch(inferenceDispatcher) {
            try {
                val bitmap = convertYUVToBitmap(data, width, height, format)
                objectDetectorHelper.detect(bitmap, 0)
            } catch (e: Exception) {
                Log.e(TAG, "Error processing frame: ${e.message}")
            }
        }
    }

    private fun convertYUVToBitmap(data: ByteArray, width: Int, height: Int, format: IPreviewDataCallBack.DataFormat): Bitmap {
        return if (format == IPreviewDataCallBack.DataFormat.RGBA) {
            val pixels = IntArray(width * height)
            for (i in 0 until width * height) {
                val r = data[i * 4].toInt() and 0xFF
                val g = data[i * 4 + 1].toInt() and 0xFF
                val b = data[i * 4 + 2].toInt() and 0xFF
                val a = data[i * 4 + 3].toInt() and 0xFF
                pixels[i] = (a shl 24) or (r shl 16) or (g shl 8) or b
            }

            Bitmap.createBitmap(pixels, width, height, Bitmap.Config.ARGB_8888)
        } else {
            val yuvImage = YuvImage(data, ImageFormat.NV21, width, height, null)
            val out = ByteArrayOutputStream()
            yuvImage.compressToJpeg(Rect(0, 0, width, height), 100, out)
            val imageBytes = out.toByteArray()
            BitmapFactory.decodeByteArray(imageBytes, 0, imageBytes.size)
        }
    }

    private fun initObjectDetector() {
        lifecycleScope.launch(inferenceDispatcher) {
            objectDetectorHelper = ObjectDetectorHelper(
                context = requireContext(),
                objectDetectorListener = object : ObjectDetectorHelper.DetectorListener {
                    override fun onError(error: String) {
                        Log.e(TAG, "Object Detection Error: $error")
                        ToastUtils.show("Object Detection Error: $error")
                    }

                    override fun onResults(
                        results: MutableList<Detection>?,
                        inferenceTime: Long,
                        imageHeight: Int,
                        imageWidth: Int
                    ) {
                        results?.let { detections ->
                            if (detections.isNotEmpty()) {
                                Log.d(TAG, "Detections found: ${detections.size}")
                                updateOverlayView(detections, imageHeight, imageWidth)

                                handleDetections(detections)
                            } else {
                                Log.d(TAG, "No detections found.")
                            }
                        }
                    }
                }
            )
        }
    }

    private fun handleDetections(detections: List<Detection>) {
        val currentDetections = mutableSetOf<String>()

        for (detection in detections) {
            detection.categories.firstOrNull()?.label?.let { currentDetections.add(it) }
        }

        val newDetections = currentDetections.subtract(previousDetections)

        for (detection in newDetections) {
            if (shouldSpeakNow()) {
                Log.d(TAG, "Detected new object: $detection")
                if (!textToSpeech.isSpeaking) {
                    textToSpeech.speak(detection, TextToSpeech.QUEUE_FLUSH, null, detection.hashCode().toString())
                } else {
                    speechQueue.offer(detection)
                }
            }
        }

        previousDetections = currentDetections
    }

    private fun updateOverlayView(detections: List<Detection>, imageHeight: Int, imageWidth: Int) {
        mViewBinding.overlay.setResults(detections, imageHeight, imageWidth)
    }

    private fun stopLiveObjectDetection() {
        isObjectDetectionActive = false
        getCurrentCamera()?.removePreviewDataCallBack(object : IPreviewDataCallBack {
            override fun onPreviewData(data: ByteArray?, width: Int, height: Int, format: IPreviewDataCallBack.DataFormat) {}
        })
    }

    override fun initView() {
        super.initView()

        mViewBinding.lensFacingBtn1.setOnClickListener(this)
        mViewBinding.effectsBtn.setOnClickListener(this)
        mViewBinding.cameraTypeBtn.setOnClickListener(this)
        mViewBinding.settingsBtn.setOnClickListener(this)
        mViewBinding.voiceBtn.setOnClickListener(this)
        mViewBinding.resolutionBtn.setOnClickListener(this)
        mViewBinding.albumPreviewIv.setOnClickListener(this)
        mViewBinding.captureBtn.setOnViewClickListener(this)
        mViewBinding.albumPreviewIv.setTheme(PreviewImageView.Theme.DARK)

        mViewBinding.btnStartTextDetection.setOnClickListener {
            startTextDetection()
        }

        mViewBinding.btnStopTextDetection.setOnClickListener {
            stopAllDetections()
        }

        switchLayoutClick()
    }

    override fun initData() {
        super.initData()
        initObjectDetector()
        EventBus.with<Int>(BusKey.KEY_FRAME_RATE).observe(this) {
            mViewBinding.frameRateTv.text = "frame rate:  $it fps"
        }

        EventBus.with<Boolean>(BusKey.KEY_RENDER_READY).observe(this) { ready ->
            if (!ready) return@observe
            getDefaultEffect()?.apply {
                when (getClassifyId()) {
                    CameraEffect.CLASSIFY_ID_FILTER -> {
                        val filterId = -1
                        if (filterId != -99) {
                            removeRenderEffect(this)
                            mEffectDataList.find {
                                it.id == filterId
                            }?.also {
                                it.effect?.let { effect ->
                                    addRenderEffect(effect)
                                }
                            }
                        }
                    }
                    CameraEffect.CLASSIFY_ID_ANIMATION -> {
                        val animId = -1
                        if (animId != -99) {
                            removeRenderEffect(this)
                            mEffectDataList.find {
                                it.id == animId
                            }?.also {
                                it.effect?.let { effect ->
                                    addRenderEffect(effect)
                                }
                            }
                        }
                    }
                    else -> throw IllegalStateException("Unsupported classify")
                }
            }
        }
    }

    private fun startTextDetection() {
        if (!isTextRecognitionActive) {  // Check if already active
            isTextRecognitionActive = true
            Toast.makeText(requireContext(), "Text Detection Started", Toast.LENGTH_SHORT).show()

            lifecycleScope.launch(Dispatchers.Default) {
                while (isTextRecognitionActive) {
                    captureFrameForTextDetection()
                    delay(DETECTION_INTERVAL_MS)
                }
            }
        }
    }


    private suspend fun captureFrameForTextDetection() {
        withContext(Dispatchers.Default) {
            val currentCamera = getCurrentCamera() as? CameraUVC ?: return@withContext
            currentCamera.captureImage(object : ICaptureCallBack {
                override fun onBegin() {}

                override fun onError(error: String?) {
                    ToastUtils.show("Error capturing frame: $error")
                }

                override fun onComplete(path: String?) {
                    path?.let {
                        val bitmap = BitmapFactory.decodeFile(it)
                        detectText(bitmap)

                        scheduleFileDeletion(it, 10_000L)
                    }
                }
            })
        }
    }


    private fun scheduleFileDeletion(filePath: String, delayMillis: Long) {
        Handler(Looper.getMainLooper()).postDelayed({
            val file = File(filePath)
            if (file.exists()) {

                val deleted = file.delete()
                if (deleted) {
                    removeImageFromGallery(filePath)
                    Log.d(TAG, "File deleted successfully: $filePath")
                } else {
                    Log.e(TAG, "Failed to delete file: $filePath")
                }
            }
        }, delayMillis)
    }

    private fun removeImageFromGallery(filePath: String) {

        val contentResolver = requireContext().contentResolver

        val uri = MediaStore.Images.Media.EXTERNAL_CONTENT_URI
        val selection = "${MediaStore.Images.Media.DATA} = ?"
        val selectionArgs = arrayOf(filePath)

        val rowsDeleted = contentResolver.delete(uri, selection, selectionArgs)

        if (rowsDeleted > 0) {
            Log.d(TAG, "MediaStore updated successfully for file: $filePath")
        } else {
            Log.e(TAG, "Failed to update MediaStore for file: $filePath")
        }
    }

    private fun detectText(bitmap: Bitmap) {
        val inputImage = InputImage.fromBitmap(bitmap, 0)

        textRecognizer.process(inputImage)
            .addOnSuccessListener { visionText ->
                val detectedText = visionText.text
                if (detectedText.isNotEmpty()) {
                    readDetectedText(detectedText)
                    updateOverlayViewForText(visionText.textBlocks, bitmap.height, bitmap.width)
                }
            }
            .addOnFailureListener { e ->
                Log.e(TAG, "Text Recognition Error: $e")
            }
    }

    private fun readDetectedText(text: String) {
        if (text.isEmpty() || !shouldSpeakNow()) {
            return
        }

        if (!textToSpeech.isSpeaking) {
            textToSpeech.speak(text, TextToSpeech.QUEUE_FLUSH, null, text.hashCode().toString())
        } else {
            speechQueue.offer(text)
        }
    }

    private fun updateOverlayViewForText(textBlocks: List<com.google.mlkit.vision.text.Text.TextBlock>, imageHeight: Int, imageWidth: Int) {

        mViewBinding.overlay.setResults(
            emptyList(), imageHeight, imageWidth, textBlocks
        )
    }

    private fun stopAllDetections() {
        stopObjectDetection()
        stopTextDetection()
        Toast.makeText(requireContext(), "Detection Stopped", Toast.LENGTH_SHORT).show()
    }

    private fun stopTextDetection() {
        if (isTextRecognitionActive) {
            isTextRecognitionActive = false
            lifecycleScope.coroutineContext.cancelChildren()  // Cancels all child coroutines
            Toast.makeText(requireContext(), "Text Detection Stopped", Toast.LENGTH_SHORT).show()
        }
    }


    override fun onCameraState(
        self: MultiCameraClient.ICamera,
        code: ICameraStateCallBack.State,
        msg: String?
    ) {
        when (code) {
            ICameraStateCallBack.State.OPENED -> {
                handleCameraOpened()
            }
            ICameraStateCallBack.State.CLOSED -> handleCameraClosed()
            ICameraStateCallBack.State.ERROR -> handleCameraError(msg)
        }
    }

    private fun handleCameraError(msg: String?) {
        mViewBinding.uvcLogoIv.visibility = View.VISIBLE
        mViewBinding.frameRateTv.visibility = View.GONE
        ToastUtils.show("camera opened error: $msg")
    }

    private fun handleCameraClosed() {
        mViewBinding.uvcLogoIv.visibility = View.VISIBLE
        mViewBinding.frameRateTv.visibility = View.GONE
        ToastUtils.show("camera closed success")
        stopAllDetections()
    }

    private fun handleCameraOpened() {
        mViewBinding.uvcLogoIv.visibility = View.GONE
        mViewBinding.frameRateTv.visibility = View.VISIBLE
        mViewBinding.brightnessSb.max = (getCurrentCamera() as? CameraUVC)?.getBrightnessMax() ?: 100
        mViewBinding.brightnessSb.progress = (getCurrentCamera() as? CameraUVC)?.getBrightness() ?: 0
        Logger.i(TAG, "max = ${mViewBinding.brightnessSb.max}, progress = ${mViewBinding.brightnessSb.progress}")
        mViewBinding.brightnessSb.setOnSeekBarChangeListener(object : SeekBar.OnSeekBarChangeListener {
            override fun onProgressChanged(seekBar: SeekBar?, progress: Int, fromUser: Boolean) {
                (getCurrentCamera() as? CameraUVC)?.setBrightness(progress)
            }

            override fun onStartTrackingTouch(seekBar: SeekBar?) {}

            override fun onStopTrackingTouch(seekBar: SeekBar?) {}
        })
        ToastUtils.show("camera opened success")
    }

    private fun switchLayoutClick() {
        mViewBinding.takePictureModeTv.setOnClickListener {
            if (mCameraMode == CaptureMediaView.CaptureMode.MODE_CAPTURE_PIC) {
                return@setOnClickListener
            }
            mCameraMode = CaptureMediaView.CaptureMode.MODE_CAPTURE_PIC
            updateCameraModeSwitchUI()
        }
        mViewBinding.recordVideoModeTv.setOnClickListener {
            if (mCameraMode == CaptureMediaView.CaptureMode.MODE_CAPTURE_VIDEO) {
                return@setOnClickListener
            }
            mCameraMode = CaptureMediaView.CaptureMode.MODE_CAPTURE_VIDEO
            updateCameraModeSwitchUI()
        }
        mViewBinding.recordAudioModeTv.setOnClickListener {
            if (mCameraMode == CaptureMediaView.CaptureMode.MODE_CAPTURE_AUDIO) {
                return@setOnClickListener
            }
            mCameraMode = CaptureMediaView.CaptureMode.MODE_CAPTURE_AUDIO
            updateCameraModeSwitchUI()
        }
        updateCameraModeSwitchUI()
        showRecentMedia()
    }

    override fun getCameraView(): IAspectRatio {
        return AspectRatioTextureView(requireContext())
    }

    override fun getCameraViewContainer(): ViewGroup {
        return mViewBinding.cameraViewContainer
    }

    override fun getRootView(inflater: LayoutInflater, container: ViewGroup?): View {
        mViewBinding = FragmentUsbBinding.inflate(inflater, container, false)
        return mViewBinding.root
    }

    override fun getGravity(): Int = Gravity.CENTER

    override fun onViewClick(mode: CaptureMediaView.CaptureMode?) {
        if (!isCameraOpened()) {
            ToastUtils.show("camera not worked!")
            return
        }
        when (mode) {
            CaptureMediaView.CaptureMode.MODE_CAPTURE_PIC -> captureImage()
            CaptureMediaView.CaptureMode.MODE_CAPTURE_AUDIO -> captureAudio()
            else -> captureVideo()
        }
    }

    private fun captureAudio() {
        if (isCapturingVideoOrAudio) {
            captureAudioStop()
            return
        }
        captureAudioStart(object : ICaptureCallBack {
            override fun onBegin() {
                isCapturingVideoOrAudio = true
                mViewBinding.captureBtn.setCaptureVideoState(CaptureMediaView.CaptureVideoState.DOING)
                mViewBinding.modeSwitchLayout.visibility = View.GONE
                mViewBinding.toolbarGroup.visibility = View.GONE
                mViewBinding.albumPreviewIv.visibility = View.GONE
                mViewBinding.lensFacingBtn1.visibility = View.GONE
                mViewBinding.recTimerLayout.visibility = View.VISIBLE
                startMediaTimer()
            }

            override fun onError(error: String?) {
                ToastUtils.show(error ?: "Unknown error")
                isCapturingVideoOrAudio = false
                mViewBinding.captureBtn.setCaptureVideoState(CaptureMediaView.CaptureVideoState.UNDO)
                stopMediaTimer()
            }

            override fun onComplete(path: String?) {
                isCapturingVideoOrAudio = false
                mViewBinding.captureBtn.setCaptureVideoState(CaptureMediaView.CaptureVideoState.UNDO)
                mViewBinding.modeSwitchLayout.visibility = View.VISIBLE
                mViewBinding.toolbarGroup.visibility = View.VISIBLE
                mViewBinding.albumPreviewIv.visibility = View.VISIBLE
                mViewBinding.lensFacingBtn1.visibility = View.VISIBLE
                mViewBinding.recTimerLayout.visibility = View.GONE
                stopMediaTimer()
                ToastUtils.show(path ?: "error")
            }
        })
    }

    private fun captureVideo() {
        if (isCapturingVideoOrAudio) {
            captureVideoStop()
            return
        }
        captureVideoStart(object : ICaptureCallBack {
            override fun onBegin() {
                isCapturingVideoOrAudio = true
                mViewBinding.captureBtn.setCaptureVideoState(CaptureMediaView.CaptureVideoState.DOING)
                mViewBinding.modeSwitchLayout.visibility = View.GONE
                mViewBinding.toolbarGroup.visibility = View.GONE
                mViewBinding.albumPreviewIv.visibility = View.GONE
                mViewBinding.lensFacingBtn1.visibility = View.GONE
                mViewBinding.recTimerLayout.visibility = View.VISIBLE
                startMediaTimer()
            }

            override fun onError(error: String?) {
                ToastUtils.show(error ?: "Unknown error")
                isCapturingVideoOrAudio = false
                mViewBinding.captureBtn.setCaptureVideoState(CaptureMediaView.CaptureVideoState.UNDO)
                stopMediaTimer()
            }

            override fun onComplete(path: String?) {
                ToastUtils.show(path ?: "")
                isCapturingVideoOrAudio = false
                mViewBinding.captureBtn.setCaptureVideoState(CaptureMediaView.CaptureVideoState.UNDO)
                mViewBinding.modeSwitchLayout.visibility = View.VISIBLE
                mViewBinding.toolbarGroup.visibility = View.VISIBLE
                mViewBinding.albumPreviewIv.visibility = View.VISIBLE
                mViewBinding.lensFacingBtn1.visibility = View.VISIBLE
                mViewBinding.recTimerLayout.visibility = View.GONE
                showRecentMedia(false)
                stopMediaTimer()
            }
        })
    }

    private fun captureImage() {
        captureImage(object : ICaptureCallBack {
            override fun onBegin() {
                mViewBinding.albumPreviewIv.showImageLoadProgress()
                mViewBinding.albumPreviewIv.setNewImageFlag(true)
            }

            override fun onError(error: String?) {
                ToastUtils.show(error ?: "Unknown error")
                mViewBinding.albumPreviewIv.cancelAnimation()
                mViewBinding.albumPreviewIv.setNewImageFlag(false)
            }

            override fun onComplete(path: String?) {
                showRecentMedia(true)
                mViewBinding.albumPreviewIv.setNewImageFlag(false)
            }
        })
    }

    override fun onDestroyView() {
        super.onDestroyView()
        mMoreMenu?.dismiss()
        stopAllDetections()
        stopLiveObjectDetection()
        inferenceDispatcher.close()
        speechRecognizer.destroy()

        lifecycleScope.coroutineContext.cancelChildren()
    }

    private fun stopObjectDetection() {
        if (isObjectDetectionActive) {
            isObjectDetectionActive = false
            getCurrentCamera()?.removePreviewDataCallBack(object : IPreviewDataCallBack {
                override fun onPreviewData(data: ByteArray?, width: Int, height: Int, format: IPreviewDataCallBack.DataFormat) {}
            })
            Toast.makeText(requireContext(), "Object Detection Stopped", Toast.LENGTH_SHORT).show()
        }
    }


    override fun onClick(v: View?) {
        if (!isCameraOpened()) {
            ToastUtils.show("camera not worked!")
            return
        }
        clickAnimation(v!!, object : AnimatorListenerAdapter() {
            override fun onAnimationEnd(animation: Animator) {
                when (v) {
                    mViewBinding.lensFacingBtn1 -> {
                        getCurrentCamera()?.let { strategy ->
                            if (strategy is CameraUVC) {
                                showUsbDevicesDialog(getDeviceList(), strategy.getUsbDevice())
                                return
                            }
                        }
                    }
                    mViewBinding.voiceBtn -> playMic()
                    mViewBinding.resolutionBtn -> showResolutionDialog()
                    mViewBinding.albumPreviewIv -> goToGallery()
                    else -> {
                        // No need to trigger detection manually
                    }
                }
            }
        })
    }

    private fun showUsbDevicesDialog(usbDeviceList: MutableList<UsbDevice>?, curDevice: UsbDevice?) {
        if (usbDeviceList.isNullOrEmpty()) {
            ToastUtils.show("Get usb device failed")
            return
        }
        val list = arrayListOf<String>()
        var selectedIndex: Int = -1
        for (index in usbDeviceList.indices) {
            val dev = usbDeviceList[index]
            val devName = if (Build.VERSION.SDK_INT >= Build.VERSION_CODES.LOLLIPOP && !dev.productName.isNullOrEmpty()) {
                "${dev.productName}(${curDevice?.deviceId})"
            } else {
                dev.deviceName
            }
            val curDevName = if (Build.VERSION.SDK_INT >= Build.VERSION_CODES.LOLLIPOP && !curDevice?.productName.isNullOrEmpty()) {
                "${curDevice!!.productName}(${curDevice.deviceId})"
            } else {
                curDevice?.deviceName
            }
            if (devName == curDevName) {
                selectedIndex = index
            }
            list.add(devName)
        }
        MaterialDialog(requireContext()).show {
            listItemsSingleChoice(
                items = list,
                initialSelection = selectedIndex
            ) { _, index, _ ->
                if (selectedIndex == index) {
                    return@listItemsSingleChoice
                }
                switchCamera(usbDeviceList[index])
            }
        }
    }

    private fun showResolutionDialog() {
        mMoreMenu?.dismiss()
        getAllPreviewSizes().let { previewSizes ->
            if (previewSizes.isNullOrEmpty()) {
                ToastUtils.show("Get camera preview size failed")
                return
            }
            val list = arrayListOf<String>()
            var selectedIndex: Int = -1
            for (index in previewSizes.indices) {
                val w = previewSizes[index].width
                val h = previewSizes[index].height
                getCurrentPreviewSize()?.apply {
                    if (width == w && height == h) {
                        selectedIndex = index
                    }
                }
                list.add("$w x $h")
            }
            MaterialDialog(requireContext()).show {
                listItemsSingleChoice(
                    items = list,
                    initialSelection = selectedIndex
                ) { _, index, _ ->
                    if (selectedIndex == index) {
                        return@listItemsSingleChoice
                    }
                    updateResolution(previewSizes[index].width, previewSizes[index].height)
                }
            }
        }
    }

    private fun goToGallery() {
        try {
            Intent(Intent.ACTION_VIEW, MediaStore.Images.Media.EXTERNAL_CONTENT_URI).apply {
                startActivity(this)
            }
        } catch (e: Exception) {
            ToastUtils.show("open error: ${e.localizedMessage}")
        }
    }

    private fun playMic() {
        if (isPlayingMic) {
            stopPlayMic()
            return
        }
        startPlayMic(object : IPlayCallBack {
            override fun onBegin() {
                mViewBinding.voiceBtn.setImageResource(R.mipmap.camera_voice_on)
                isPlayingMic = true
            }

            override fun onError(error: String) {
                mViewBinding.voiceBtn.setImageResource(R.mipmap.camera_voice_off)
                isPlayingMic = false
            }

            override fun onComplete() {
                mViewBinding.voiceBtn.setImageResource(R.mipmap.camera_voice_off)
                isPlayingMic = false
            }
        })
    }

    private fun showRecentMedia(isImage: Boolean? = null) {
        // Implement logic to show recent media if needed
    }

    private fun updateCameraModeSwitchUI() {
        mViewBinding.modeSwitchLayout.children.forEach { it ->
            val tabTv = it as TextView
            val isSelected = tabTv.id == mCameraModeTabMap[mCameraMode]
            val typeface = if (isSelected) Typeface.BOLD else Typeface.NORMAL
            tabTv.typeface = Typeface.defaultFromStyle(typeface)
            if (isSelected) {
                0xFFFFFFFF
            } else {
                0xFFD7DAE1
            }.also {
                tabTv.setTextColor(it.toInt())
            }
            tabTv.setShadowLayer(
                Utils.dp2px(requireContext(), 1F).toFloat(),
                0F,
                0F,
                0xBF000000.toInt()
            )

            if (isSelected) {
                R.mipmap.camera_preview_dot_blue
            } else {
                R.drawable.camera_bottom_dot_transparent
            }.also {
                TextViewCompat.setCompoundDrawablesRelativeWithIntrinsicBounds(tabTv, 0, 0, 0, it)
            }
            tabTv.compoundDrawablePadding = 1
        }
        mViewBinding.captureBtn.setCaptureViewTheme(CaptureMediaView.CaptureViewTheme.THEME_WHITE)
        val height = mViewBinding.controlPanelLayout.height
        mViewBinding.captureBtn.setCaptureMode(mCameraMode)
        if (mCameraMode == CaptureMediaView.CaptureMode.MODE_CAPTURE_PIC) {
            val translationX = ObjectAnimator.ofFloat(
                mViewBinding.controlPanelLayout,
                "translationY",
                height.toFloat(),
                0.0f
            )
            translationX.duration = 600
            translationX.addListener(object : AnimatorListenerAdapter() {
                override fun onAnimationStart(animation: Animator) {
                    super.onAnimationStart(animation)
                    mViewBinding.controlPanelLayout.visibility = View.VISIBLE
                }
            })
            translationX.start()
        } else {
            val translationX = ObjectAnimator.ofFloat(
                mViewBinding.controlPanelLayout,
                "translationY",
                0.0f,
                height.toFloat()
            )
            translationX.duration = 600
            translationX.addListener(object : AnimatorListenerAdapter() {
                override fun onAnimationEnd(animation: Animator) {
                    super.onAnimationEnd(animation)
                    mViewBinding.controlPanelLayout.visibility = View.INVISIBLE
                }
            })
            translationX.start()
        }
    }

    private fun clickAnimation(v: View, listener: Animator.AnimatorListener) {
        val scaleXAnim: ObjectAnimator = ObjectAnimator.ofFloat(v, "scaleX", 1.0f, 0.4f, 1.0f)
        val scaleYAnim: ObjectAnimator = ObjectAnimator.ofFloat(v, "scaleY", 1.0f, 0.4f, 1.0f)
        val alphaAnim: ObjectAnimator = ObjectAnimator.ofFloat(v, "alpha", 1.0f, 0.4f, 1.0f)
        val animatorSet = AnimatorSet()
        animatorSet.duration = 150
        animatorSet.addListener(listener)
        animatorSet.playTogether(scaleXAnim, scaleYAnim, alphaAnim)
        animatorSet.start()
    }

    private fun startMediaTimer() {
        mRecTimer?.cancel()
        mRecTimer = Timer().apply {
            schedule(object : TimerTask() {
                override fun run() {
                    mRecSeconds++
                    if (mRecSeconds >= 60) {
                        mRecSeconds = 0
                        mRecMinute++
                    }
                    if (mRecMinute >= 60) {
                        mRecMinute = 0
                        mRecHours++
                        if (mRecHours >= 24) {
                            mRecHours = 0
                            mRecMinute = 0
                            mRecSeconds = 0
                        }
                    }
                    mMainHandler.sendEmptyMessage(WHAT_START_TIMER)
                }
            }, 1000, 1000)
        }
    }

    override fun onDestroy() {
        textToSpeech.stop()
        textToSpeech.shutdown()
        textRecognizer.close()
        super.onDestroy()
    }

    private fun stopMediaTimer() {
        mRecTimer?.cancel()
        mRecTimer = null
        mRecHours = 0
        mRecMinute = 0
        mRecSeconds = 0
        mMainHandler.sendEmptyMessage(WHAT_STOP_TIMER)
    }

    private fun calculateTime(seconds: Int, minute: Int, hour: Int? = null): String {
        return buildString {
            if (hour != null) {
                append(if (hour < 10) "0$hour" else hour.toString())
                append(":")
            }
            append(if (minute < 10) "0$minute" else minute.toString())
            append(":")
            append(if (seconds < 10) "0$seconds" else seconds.toString())
        }
    }

    companion object {
        private const val TAG = "UsbFragment"
        private const val WHAT_START_TIMER = 0x00
        private const val WHAT_STOP_TIMER = 0x01
        private const val DETECTION_INTERVAL_MS = 2000L
    }
}








































package com.aditya.`object`

import android.Manifest
import android.content.BroadcastReceiver
import android.content.Context
import android.content.Intent
import android.content.IntentFilter
import android.content.pm.PackageManager
import android.hardware.usb.UsbDevice
import android.hardware.usb.UsbManager
import android.os.Build
import android.os.Bundle
import android.os.Handler
import android.os.Looper
import android.util.Log
import android.widget.Toast
import androidx.activity.result.contract.ActivityResultContracts
import androidx.annotation.RequiresApi
import androidx.appcompat.app.AppCompatActivity
import androidx.appcompat.widget.Toolbar
import androidx.core.content.ContextCompat
import androidx.navigation.findNavController
import androidx.navigation.fragment.NavHostFragment
import androidx.navigation.ui.setupActionBarWithNavController
import com.aditya.`object`.databinding.ActivityMainBinding
import com.jiangdg.usb.USBMonitor
import com.jiangdg.uvc.UVCCamera

class MainActivity : AppCompatActivity() {

    private lateinit var activityMainBinding: ActivityMainBinding
    private lateinit var usbMonitor: USBMonitor
    private var uvcCamera: UVCCamera? = null
    private var pendingUsbDevice: UsbDevice? = null

    private val requestCameraPermissionLauncher =
        registerForActivityResult(ActivityResultContracts.RequestPermission()) { isGranted: Boolean ->
            if (isGranted) {
                Toast.makeText(this, "Camera permission granted", Toast.LENGTH_LONG).show()
                setupUsbMonitor()
            } else {
                Toast.makeText(this, "Camera permission denied", Toast.LENGTH_LONG).show()
            }
        }

    private val usbPermissionActionReceiver = object : BroadcastReceiver() {
        override fun onReceive(context: Context, intent: Intent) {
            val action = intent.action
            if (ACTION_USB_PERMISSION == action) {
                synchronized(this) {
                    val device = intent.getParcelableExtra<UsbDevice>(UsbManager.EXTRA_DEVICE)
                    if (intent.getBooleanExtra(UsbManager.EXTRA_PERMISSION_GRANTED, false)) {
                        device?.let {
                            pendingUsbDevice = it
                            navigateToUsbFragment()
                        }
                    } else {
                        Log.d("MainActivity", "Permission denied for device $device")
                    }
                }
            }
        }
    }

    override fun onCreate(savedInstanceState: Bundle?) {
        super.onCreate(savedInstanceState)
        activityMainBinding = ActivityMainBinding.inflate(layoutInflater)
        setContentView(activityMainBinding.root)

        // Set up the toolbar as the ActionBar
        val toolbar = findViewById<Toolbar>(R.id.toolbar)
        setSupportActionBar(toolbar)

        // Check for camera permission and set up USB monitor
        if (ContextCompat.checkSelfPermission(
                this,
                Manifest.permission.CAMERA
            ) == PackageManager.PERMISSION_GRANTED) {
            setupUsbMonitor()
        } else {
            requestCameraPermissionLauncher.launch(Manifest.permission.CAMERA)
        }

        // Setup action bar for navigation
        val navHostFragment =
            supportFragmentManager.findFragmentById(R.id.nav_host_fragment) as NavHostFragment
        val navController = navHostFragment.navController
        setupActionBarWithNavController(navController)
    }

    private fun setupUsbMonitor() {
        usbMonitor = USBMonitor(this, object : USBMonitor.OnDeviceConnectListener {
            override fun onAttach(device: UsbDevice) {
                if (!usbMonitor.hasPermission(device)) {
                    Log.d("MainActivity", "Requesting USB permission for device: $device")
                    usbMonitor.requestPermission(device)
                } else {
                    pendingUsbDevice = device
                    navigateToUsbFragment()
                }
            }

            override fun onDetach(device: UsbDevice?) {
                device?.let {
                    Log.d("MainActivity", "USB device detached: $device")
                    uvcCamera?.stopPreview()
                    uvcCamera?.close()
                    uvcCamera = null
                }
            }

            override fun onConnect(device: UsbDevice, ctrlBlock: USBMonitor.UsbControlBlock, createNew: Boolean) {
                if (!usbMonitor.hasPermission(device)) {
                    Toast.makeText(this@MainActivity, "USB permission denied", Toast.LENGTH_SHORT).show()
                    return
                }
                pendingUsbDevice = device
                navigateToUsbFragment()
            }

            override fun onDisconnect(device: UsbDevice, ctrlBlock: USBMonitor.UsbControlBlock) {
                Log.d("MainActivity", "USB device disconnected: $device")
                uvcCamera?.stopPreview()
                uvcCamera?.close()
                uvcCamera = null
                Toast.makeText(this@MainActivity, "USB camera disconnected", Toast.LENGTH_SHORT).show()
            }

            override fun onCancel(device: UsbDevice?) {
                Toast.makeText(this@MainActivity, "USB permission denied", Toast.LENGTH_SHORT).show()
            }
        })
        usbMonitor.register()
    }

    private fun navigateToUsbFragment() {
        // Ensure navigation is done on the main thread
        Handler(Looper.getMainLooper()).post {
            findNavController(R.id.nav_host_fragment).navigate(R.id.action_usb_to_camera)
        }
    }

    @RequiresApi(Build.VERSION_CODES.O)
    override fun onStart() {
        super.onStart()
        val filter = IntentFilter(ACTION_USB_PERMISSION)
        registerReceiver(usbPermissionActionReceiver, filter, RECEIVER_NOT_EXPORTED)
    }

    override fun onStop() {
        super.onStop()
        unregisterReceiver(usbPermissionActionReceiver)
    }

    override fun onResume() {
        super.onResume()
        usbMonitor.register()
    }

    override fun onPause() {
        super.onPause()
        usbMonitor.unregister()
    }

    override fun onDestroy() {
        super.onDestroy()
        try {
            usbMonitor.unregister()
            uvcCamera?.destroy()
        } catch (e: Exception) {
            Log.e("MainActivity", "Error during onDestroy: ${e.message}", e)
        }
    }

    override fun onBackPressed() {
        val navController = findNavController(R.id.nav_host_fragment)
        when (navController.currentDestination?.id) {
            R.id.camera_fragment -> {
                // Navigate back to USB Fragment from Camera Fragment
                navController.navigate(R.id.action_camera_to_usb)
            }
            R.id.usb_fragment -> {
                // Call super to handle exiting the app
                super.onBackPressed()
            }
            else -> super.onBackPressed()
        }
    }

    override fun onSupportNavigateUp(): Boolean {
        return findNavController(R.id.nav_host_fragment).navigateUp() || super.onSupportNavigateUp()
    }

    companion object {
        const val ACTION_USB_PERMISSION = "com.aditya.object.USB_PERMISSION"
    }
}






































<?xml version="1.0" encoding="utf-8"?>
<navigation
    xmlns:android="http://schemas.android.com/apk/res/android"
    xmlns:app="http://schemas.android.com/apk/res-auto"
    android:id="@+id/nav_graph"
    app:startDestination="@id/usb_fragment"> <!-- Changed startDestination -->

    <fragment
        android:id="@+id/permissions_fragment"
        android:name="com.aditya.object.fragment.PermissionFragment"
        android:label="PermissionsFragment" >
        <action
            android:id="@+id/action_permissions_to_camera"
            app:destination="@id/camera_fragment"
            app:popUpTo="@id/permissions_fragment"
            app:popUpToInclusive="true" />
    </fragment>

    <fragment
        android:id="@+id/camera_fragment"
        android:name="com.aditya.object.fragment.CameraFragment"
        android:label="CameraFragment" >
        <action
            android:id="@+id/action_camera_to_permissions"
            app:destination="@id/permissions_fragment"
            app:popUpTo="@id/camera_fragment"
            app:popUpToInclusive="true"/>
        <action
            android:id="@+id/action_camera_to_usb"
            app:destination="@id/usb_fragment"
            app:popUpTo="@id/camera_fragment"
            app:popUpToInclusive="true"/>
    </fragment>

    <fragment
        android:id="@+id/usb_fragment"
        android:name="com.aditya.object.fragment.UsbFragment"
        android:label="UsbFragment" >
        <action
            android:id="@+id/action_usb_to_camera"
            app:destination="@id/camera_fragment"
            app:popUpTo="@id/usb_fragment"
            app:popUpToInclusive="true"/> <!-- Changed destination to camera_fragment -->
        <action
            android:id="@+id/action_usb_to_permissions"
            app:destination="@id/permissions_fragment"
            app:popUpTo="@id/usb_fragment"
            app:popUpToInclusive="true"/>
    </fragment>
</navigation>












Internal Error occurred while analyzing this expression:
    java.lang.AssertionError: Number of arguments should not be less than number of parameters, but: parameters=6, args=4
    at org.jetbrains.kotlin.types.IndexedParametersSubstitution.&lt;init&gt;(TypeSubstitution.kt:119)
    at org.jetbrains.kotlin.types.IndexedParametersSubstitution.&lt;init&gt;(TypeSubstitution.kt:113)
   at org.jetbrains.kotlin.types.IndexedParametersSubstitution.&lt;init&gt;(TypeSubstitution.kt:127)
    at org.jetbrains.kotlin.types.TypeConstructorSubstitution$Companion.create(TypeSubstitution.kt:99)
    at org.jetbrains.kotlin.types.KotlinTypeFactory.computeMemberScope(KotlinTypeFactory.kt:57)
    at org.jetbrains.kotlin.types.KotlinTypeFactory.simpleType(KotlinTypeFactory.kt:90)
    at org.jetbrains.kotlin.types.KotlinTypeFactory.simpleType$default(KotlinTypeFactory.kt:77)
    at org.jetbrains.kotlin.serialization.deserialization.TypeDeserializer.simpleType(TypeDeserializer.kt:126)
    at org.jetbrains.kotlin.serialization.deserialization.TypeDeserializer.type(TypeDeserializer.kt:68)
    at org.jetbrains.kotlin.serialization.deserialization.descriptors.DeserializedClassDescriptor$DeserializedClassTypeConstructor.computeSupertypes(DeserializedClassDescriptor.kt:242)
    at org.jetbrains.kotlin.types.AbstractTypeConstructor$supertypes$1.invoke(AbstractTypeConstructor.kt:78)
    at org.jetbrains.kotlin.types.AbstractTypeConstructor$supertypes$1.invoke(AbstractTypeConstructor.kt:77)
    at org.jetbrains.kotlin.storage.LockBasedStorageManager$LockBasedLazyValue.invoke(LockBasedStorageManager.java:408)
    at org.jetbrains.kotlin.storage.LockBasedStorageManager$LockBasedLazyValueWithPostCompute.invoke(LockBasedStorageManager.java:481)
    at org.jetbrains.kotlin.storage.LockBasedStorageManager$LockBasedNotNullLazyValueWithPostCompute.invoke(LockBasedStorageManager.java:512)
    at org.jetbrains.kotlin.types.AbstractTypeConstructor.getSupertypes(AbstractTypeConstructor.kt:27)
    at org.jetbrains.kotlin.serialization.deserialization.descriptors.DeserializedClassDescriptor$DeserializedClassMemberScope.getNonDeclaredFunctionNames(DeserializedClassDes...



plugins {
    alias(libs.plugins.android.application)
    alias(libs.plugins.jetbrains.kotlin.android)
    id ("kotlin-kapt")
    id ("kotlin-android")
    id ("androidx.navigation.safeargs") version "2.7.7"
    id("de.undercouch.download") version "5.6.0"
}

apply(plugin= "androidx.navigation.safeargs")

android {
    namespace = "com.aditya.object"
    compileSdk = 35

    defaultConfig {
        applicationId = "com.aditya.object"
        minSdk = 24
        targetSdk = 35
        versionCode = 1
        versionName = "1.0"

        testInstrumentationRunner = "androidx.test.runner.AndroidJUnitRunner"
    }

    buildTypes {
        release {
            isMinifyEnabled = false
            proguardFiles(
                getDefaultProguardFile("proguard-android-optimize.txt"),
                "proguard-rules.pro"
            )
        }
    }

    buildFeatures {
        viewBinding = true
        dataBinding = true
    }
//    androidResources {
//        noCompress = 'tflite'
//    }
    compileOptions {
        sourceCompatibility = JavaVersion.VERSION_1_8
        targetCompatibility = JavaVersion.VERSION_1_8
    }

    kotlinOptions {
        jvmTarget = "1.8"
    }
}

dependencies {



    implementation(libs.androidx.core.ktx)
    implementation(libs.androidx.appcompat)
    implementation(libs.material)
    implementation(libs.androidx.activity)
    implementation(libs.androidx.constraintlayout)
    implementation(project(":libuvc"))
    implementation(project(":libausbc"))
    implementation(libs.androidx.room.common)
    implementation(libs.androidx.room.ktx)

    annotationProcessor ("androidx.room:room-compiler:2.6.1")
    implementation("androidx.room:room-runtime:2.6.1")
    implementation("androidx.room:room-ktx:2.6.1")
    kapt ("androidx.room:room-compiler:2.6.1")

    implementation(libs.firebase.crashlytics.buildtools)
    testImplementation(libs.junit)
    androidTestImplementation(libs.androidx.junit)
    androidTestImplementation(libs.androidx.espresso.core)

//    implementation (project(":libausbc"))
    implementation(project(":libuvc"))
//    implementation(project(":libausbc"))
//
//    implementation ("org.jitsi.react:jitsi-meet-sdk:3.10.2")
    implementation("androidx.databinding:databinding-runtime:8.5.2")

    implementation ("com.afollestad.material-dialogs:core:3.3.0")

    // App compat and UI things
    implementation ("androidx.lifecycle:lifecycle-runtime-ktx:2.8.4")
    implementation ("com.google.android.material:material:1.13.0-alpha05")
    implementation ("androidx.localbroadcastmanager:localbroadcastmanager:1.1.0")
    // Navigation library
    implementation ("androidx.navigation:navigation-fragment-ktx:2.7.7")
    implementation ("androidx.navigation:navigation-ui-ktx:2.7.7")
    // CameraX core library
    implementation ("androidx.camera:camera-core:1.4.0-rc01")
    // CameraX Camera2 extensions
    implementation ("androidx.camera:camera-camera2:1.4.0-rc01")
    // CameraX Lifecycle library
    implementation ("androidx.camera:camera-lifecycle:1.4.0-rc01")
    // CameraX View class
    implementation ("androidx.camera:camera-view:1.4.0-rc01")
    //WindowManager
    implementation ("androidx.window:window:1.3.0")
    implementation ("org.tensorflow:tensorflow-lite-task-vision:0.4.4")
    // Import the GPU delegate plugin Library for GPU inference
    implementation ("org.tensorflow:tensorflow-lite-gpu-delegate-plugin:0.4.4")
    implementation ("org.tensorflow:tensorflow-lite-gpu:2.16.1")

    implementation ("org.tensorflow:tensorflow-lite:2.16.1")
    implementation ("com.google.mlkit:text-recognition:16.0.1")
//    implementation ("com.google.mlkit:vision:19.0.2")
    implementation("com.google.mlkit:vision-common:17.3.0")

    implementation("androidx.camera:camera-mlkit-vision:1.4.0-rc01")
    // If you want to additionally use the CameraX Extensions library
    implementation("androidx.camera:camera-extensions:1.4.0-rc01")
    implementation("com.google.mlkit:text-recognition:16.0.1")

    implementation ("com.google.code.gson:gson:2.11.0")

    implementation ("com.google.android.gms:play-services-vision:20.1.3")

    implementation ("com.google.android.gms:play-services-maps:19.0.0")
    implementation ("com.google.android.gms:play-services-location:21.3.0")

    // Face features
    implementation ("com.google.mlkit:face-detection:16.1.7")


    // Or comment the dependency above and uncomment the dependency below to
    // use unbundled model that depends on Google Play Services
    implementation ("com.google.android.gms:play-services-mlkit-face-detection:17.1.0")

}

project.ext["ASSET_DIR"] = "$projectDir/src/main/assets/"
project.ext["TEST_ASSET_DIR"] = "$projectDir/src/androidTest/assets/"
apply(from = "download_tasks.gradle")


 implementation(libs.androidx.core.ktx)
    implementation(libs.androidx.appcompat)
    implementation(libs.material)
    implementation(libs.androidx.activity)
    implementation(libs.androidx.constraintlayout)
    implementation(project(":libuvc"))
    implementation(project(":libausbc"))
    testImplementation(libs.junit)
    androidTestImplementation(libs.androidx.junit)
    androidTestImplementation(libs.androidx.espresso.core)


//    implementation(fileTree(mapOf("dir" to "libs", "include" to listOf( "*.aar"))))


    // Required for Ola-MapsSdk
    implementation("com.moengage:moe-android-sdk:13.04.00")
    implementation("org.maplibre.gl:android-sdk:11.1.0")
    implementation("org.maplibre.gl:android-sdk-directions-models:5.9.0")
    implementation("org.maplibre.gl:android-sdk-services:5.9.0")
    implementation("org.maplibre.gl:android-sdk-turf:6.0.1")
    implementation("org.maplibre.gl:android-plugin-markerview-v9:3.0.0")
    implementation("org.maplibre.gl:android-plugin-annotation-v9:3.0.0")

    implementation("androidx.databinding:databinding-runtime:8.5.2")
    implementation("com.afollestad.material-dialogs:core:3.3.0")
    implementation("androidx.lifecycle:lifecycle-runtime-ktx:2.8.4")
    implementation("com.google.android.material:material:1.13.0-alpha05")
    implementation("androidx.localbroadcastmanager:localbroadcastmanager:1.1.0")
    implementation("androidx.navigation:navigation-fragment-ktx:2.7.7")
    implementation("androidx.navigation:navigation-ui-ktx:2.7.7")
    implementation("androidx.camera:camera-core:1.4.0-rc01")
    implementation("androidx.camera:camera-camera2:1.4.0-rc01")
    implementation("androidx.camera:camera-lifecycle:1.4.0-rc01")
    implementation("androidx.camera:camera-view:1.4.0-rc01")
    implementation("androidx.window:window:1.3.0")
    implementation("org.tensorflow:tensorflow-lite-task-vision:0.4.4")
    implementation("org.tensorflow:tensorflow-lite-gpu-delegate-plugin:0.4.4")
    implementation("org.tensorflow:tensorflow-lite-gpu:2.16.1")
    implementation("com.google.mlkit:text-recognition:16.0.1")
    implementation("com.google.mlkit:vision-common:17.3.0")
    implementation("androidx.camera:camera-mlkit-vision:1.4.0-rc01")
    implementation("androidx.camera:camera-extensions:1.4.0-rc01")
    implementation("com.google.code.gson:gson:2.11.0")
    implementation("com.google.android.gms:play-services-vision:20.1.3")
    implementation("com.google.android.gms:play-services-maps:19.0.0")
    implementation("com.google.android.gms:play-services-location:21.3.0")
